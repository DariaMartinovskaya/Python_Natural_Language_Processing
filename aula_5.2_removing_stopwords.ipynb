{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01eec221-bdfc-42ec-a766-5b9e5dfed61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING STOPWORDS\n",
    "import csv\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4670ea3-a2db-4141-b16f-3467a0f21961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the stopwords list\n",
    "csv_file=\"stopwords.csv\"\n",
    "csv_file = \"/Users/dariamartinovskaya/Downloads/PLN/stopwords.csv\"\n",
    "with open(csv_file, 'r', encoding='utf-8') as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    stopwords = [row[0] for row in reader]\n",
    "\n",
    "#Alternatively, set the stopwords list to the NLTK list\n",
    "#stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "feb23436-2940-4d89-b5f9-daacb94138e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21754560-a98b-4f9e-bcc3-bddeff1edf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove newlines for better readability\n",
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ad4ab70-3c7a-4973-9268-669f531e58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "373ce2f4-21b0-418c-bd5c-abe1661b7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sherlock', 'Holmes', '_the_', 'woman', '.', 'seldom', 'heard', 'mention', 'name', '.', 'eyes', 'eclipses', 'predominates', 'whole', 'sex', '.', 'felt', 'emotion', 'akin', 'love', 'Irene', 'Adler', '.', 'emotions', ',', ',', 'abhorrent', 'cold', ',', 'precise', 'admirably', 'balanced', 'mind', '.', ',', 'take', ',', 'perfect', 'reasoning', 'observing', 'machine', 'world', ',', 'lover', 'placed', 'false', 'position', '.', 'spoke', 'softer', 'passions', ',', 'save', 'gibe', 'sneer', '.', 'admirable', 'observer—excellent', 'drawing', 'veil', 'men', '’', 'motives', 'actions', '.', 'trained', 'reasoner', 'admit', 'intrusions', 'own', 'delicate', 'finely', 'adjusted', 'temperament', 'introduce', 'distracting', 'factor', 'throw', 'doubt', 'mental', 'results', '.', 'Grit', 'sensitive', 'instrument', ',', 'crack', 'own', 'high-power', 'lenses', ',', 'disturbing', 'strong', 'emotion', 'nature', '.', 'woman', ',', 'woman', 'late', 'Irene', 'Adler', ',', 'dubious', 'questionable', 'memory', '.']\n"
     ]
    }
   ],
   "source": [
    "#Remove the stopwords\n",
    "words = [word for word in words if word.lower() not in stopwords]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2809a5e5-ac5c-49b3-8df9-8442cd7380c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fa0582f-049e-4581-a315-124920a35c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbef913a-5577-4282-aa6c-56a82ddde77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove newlines for better readability\n",
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f32aa1bb-176b-4425-811e-d045e637cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "419c9030-2e45-4d1b-bde7-bed2fb03841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the frequency distribution object and use it to create a list of tuples where the first element is the word and the second one is the frequency count\n",
    "freq_dist = FreqDist(word.lower() for word in words)\n",
    "words_with_frequencies = \\\n",
    "[(word, freq_dist[word]) for word in freq_dist.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ff57c92-49dd-4f37-8a5d-1970187ce75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the list of tuples by frequency\n",
    "sorted_words = sorted(words_with_frequencies, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8972e06a-2261-4c08-a0fc-b838a07da2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'never', 'good', 'nothing', 'case', 'however', 'quite', 'found', 'made', 'house', 'such', 'heard', 'way', 'yes', 'hand', 'much', 'matter', 'where', 'might', 'just', 'room', 'any', 'face', 'here', 'back', 'door', 'how', 'them', 'two', 'other', 'came', 'time', 'did', 'than', 'come', 'before', 'must', 'only', 'know', 'about', 'shall', 'think', 'more', 'over', 'us', 'well', 'am', 'or', 'may', 'they', ';', 'our', 'should', 'now', 'see', 'down', 'can', 'some', 'if', 'will', 'mr.', 'little', 'who', 'into', 'do', 'has', 'could', 'up', 'man', 'out', 'when', 'would', 'an', 'are', 'by', '!', 'were', 's', 'then', 'one', 'all', 'on', 'no', 'what', 'been', 'your', 'very', 'him', 'her', 'she', 'so', '‘', 'holmes', 'upon', 'this', 'said', 'from', 'there', 'we', 'me', 'be', 'but', 'not', 'for', '?', 'at', 'which', 'with', 'had', 'as', 'have', 'my', '’', 'is', 'his', 'was', 'you', 'he', 'it', 'that', 'in', '”', 'a', 'of', 'to', '“', 'and', 'i', '.', 'the', ',']\n"
     ]
    }
   ],
   "source": [
    "stopwords = [tuple[0] for tuple in sorted_words if tuple[1] > 100]\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aea49c35-7349-49c7-8fae-ec9df121a0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make', 'myself', 'night', 'until', 'street', 'few', 'why', 'thought', 'take', 'friend', 'lady', 'side', 'small', 'still', 'these', 'find', 'st.', 'every', 'watson', 'too', 'round', 'young', 'father', 'left', 'day', 'yet', 'first', 'once', 'took', 'its', 'eyes', 'long', 'miss', 'through', 'asked', 'most', 'saw', 'oh', 'morning', 'right', 'last', 'like', 'say', 'tell', 't', 'sherlock', 'their', 'go', 'own', 'after', 'away', 'never', 'good', 'nothing', 'case', 'however', 'quite', 'found', 'made', 'house', 'such', 'heard', 'way', 'yes', 'hand', 'much', 'matter', 'where', 'might', 'just', 'room', 'any', 'face', 'here', 'back', 'door', 'how', 'them', 'two', 'other', 'came', 'time', 'did', 'than', 'come', 'before', 'must', 'only', 'know', 'about', 'shall', 'think', 'more', 'over', 'us', 'well', 'am', 'or', 'may', 'they', ';', 'our', 'should', 'now', 'see', 'down', 'can', 'some', 'if', 'will', 'mr.', 'little', 'who', 'into', 'do', 'has', 'could', 'up', 'man', 'out', 'when', 'would', 'an', 'are', 'by', '!', 'were', 's', 'then', 'one', 'all', 'on', 'no', 'what', 'been', 'your', 'very', 'him', 'her', 'she', 'so', '‘', 'holmes', 'upon', 'this', 'said', 'from', 'there', 'we', 'me', 'be', 'but', 'not', 'for', '?', 'at', 'which', 'with', 'had', 'as', 'have', 'my', '’', 'is', 'his', 'was', 'you', 'he', 'it', 'that', 'in', '”', 'a', 'of', 'to', '“', 'and', 'i', '.', 'the', ',']\n"
     ]
    }
   ],
   "source": [
    "#Another option\n",
    "length_cutoff = int(0.02*len(sorted_words))\n",
    "stopwords = [tuple[0] for tuple in sorted_words[-length_cutoff:]]\n",
    "print(stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
