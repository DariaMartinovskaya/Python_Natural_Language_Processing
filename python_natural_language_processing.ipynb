{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0983b9-12ea-4dbf-8f61-51f43b5acd73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DIVIDING TEXT INTO SENTENCES\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt_tab\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# DIVIDING TEXT INTO SENTENCES\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8233e72d-097e-4c90-9574-fd3a6907a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always _the_ woman.\n",
      "I have seldom heard him mention her under any other name.\n",
      "In his eyes she eclipses and predominates the whole of her sex.\n",
      "It was not that he felt any emotion akin to love for Irene Adler.\n",
      "All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n",
      "He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position.\n",
      "He never spoke of the softer passions, save with a gibe and a sneer.\n",
      "They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions.\n",
      "But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results.\n",
      "Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his.\n",
      "And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\n",
      "\n",
      "Time spent: 0.1234 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dariamartinovskaya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import nltk\n",
    "\n",
    "# Run timer\n",
    "start = time.time()\n",
    "\n",
    "# Import the required resources (nltk package)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Read in the book text\n",
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Replace newlines with spaces\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# Initialize an nltk tikenizer\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "\n",
    "# Divide the text into sentences\n",
    "sentences = tokenizer.tokenize(text)\n",
    "\n",
    "# The resulting list\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "\n",
    "# Count time\n",
    "end = time.time()\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Time spent: {end - start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dacc3a8-4d57-454f-aea2-7b669d37bd81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run timer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import spacy\n",
    "\n",
    "# Run timer\n",
    "start = time.time()\n",
    "\n",
    "# Read in the book text\n",
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\"\n",
    "file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "\n",
    "# Replace newlines with spaces\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# Initialize the spaCy engine\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Divide the text into sentences\n",
    "doc = nlp(text)\n",
    "sentences = [sentence.text for sentence in doc.sents]\n",
    "\n",
    "# Print all sentences\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "\n",
    "# Count time\n",
    "end = time.time()\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Time spent: {end - start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239fbbd4-bd1e-45f3-b492-ec62a2f6ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n",
      "0.00019788742065429688 s\n"
     ]
    }
   ],
   "source": [
    "# Time code execution\n",
    "\n",
    "import time\n",
    "def main():\n",
    "    print(\"Hello, world!\")\n",
    "          \n",
    "start = time.time()\n",
    "main()\n",
    "print(\"%s s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3260e35-89b4-40ab-aab8-7e2c79c0ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To\n",
      "Sherlock\n",
      "Holmes\n",
      "she\n",
      "is\n",
      "always\n",
      "_the_\n",
      "woman\n",
      ".\n",
      "I\n",
      "have\n",
      "seldom\n",
      "heard\n",
      "him\n",
      "mention\n",
      "her\n",
      "under\n",
      "any\n",
      "other\n",
      "name\n",
      ".\n",
      "In\n",
      "his\n",
      "eyes\n",
      "she\n",
      "eclipses\n",
      "and\n",
      "predominates\n",
      "the\n",
      "whole\n",
      "of\n",
      "her\n",
      "sex\n",
      ".\n",
      "It\n",
      "was\n",
      "not\n",
      "that\n",
      "he\n",
      "felt\n",
      "any\n",
      "emotion\n",
      "akin\n",
      "to\n",
      "love\n",
      "for\n",
      "Irene\n",
      "Adler\n",
      ".\n",
      "All\n",
      "emotions\n",
      ",\n",
      "and\n",
      "that\n",
      "one\n",
      "particularly\n",
      ",\n",
      "were\n",
      "abhorrent\n",
      "to\n",
      "his\n",
      "cold\n",
      ",\n",
      "precise\n",
      "but\n",
      "admirably\n",
      "balanced\n",
      "mind\n",
      ".\n",
      "He\n",
      "was\n",
      ",\n",
      "I\n",
      "take\n",
      "it\n",
      ",\n",
      "the\n",
      "most\n",
      "perfect\n",
      "reasoning\n",
      "and\n",
      "observing\n",
      "machine\n",
      "that\n",
      "the\n",
      "world\n",
      "has\n",
      "seen\n",
      ",\n",
      "but\n",
      "as\n",
      "a\n",
      "lover\n",
      "he\n",
      "would\n",
      "have\n",
      "placed\n",
      "himself\n",
      "in\n",
      "a\n",
      "false\n",
      "position\n",
      ".\n",
      "He\n",
      "never\n",
      "spoke\n",
      "of\n",
      "the\n",
      "softer\n",
      "passions\n",
      ",\n",
      "save\n",
      "with\n",
      "a\n",
      "gibe\n",
      "and\n",
      "a\n",
      "sneer\n",
      ".\n",
      "They\n",
      "were\n",
      "admirable\n",
      "things\n",
      "for\n",
      "the\n",
      "observer—excellent\n",
      "for\n",
      "drawing\n",
      "the\n",
      "veil\n",
      "from\n",
      "men\n",
      "’\n",
      "s\n",
      "motives\n",
      "and\n",
      "actions\n",
      ".\n",
      "But\n",
      "for\n",
      "the\n",
      "trained\n",
      "reasoner\n",
      "to\n",
      "admit\n",
      "such\n",
      "intrusions\n",
      "into\n",
      "his\n",
      "own\n",
      "delicate\n",
      "and\n",
      "finely\n",
      "adjusted\n",
      "temperament\n",
      "was\n",
      "to\n",
      "introduce\n",
      "a\n",
      "distracting\n",
      "factor\n",
      "which\n",
      "might\n",
      "throw\n",
      "a\n",
      "doubt\n",
      "upon\n",
      "all\n",
      "his\n",
      "mental\n",
      "results\n",
      ".\n",
      "Grit\n",
      "in\n",
      "a\n",
      "sensitive\n",
      "instrument\n",
      ",\n",
      "or\n",
      "a\n",
      "crack\n",
      "in\n",
      "one\n",
      "of\n",
      "his\n",
      "own\n",
      "high-power\n",
      "lenses\n",
      ",\n",
      "would\n",
      "not\n",
      "be\n",
      "more\n",
      "disturbing\n",
      "than\n",
      "a\n",
      "strong\n",
      "emotion\n",
      "in\n",
      "a\n",
      "nature\n",
      "such\n",
      "as\n",
      "his\n",
      ".\n",
      "And\n",
      "yet\n",
      "there\n",
      "was\n",
      "but\n",
      "one\n",
      "woman\n",
      "to\n",
      "him\n",
      ",\n",
      "and\n",
      "that\n",
      "woman\n",
      "was\n",
      "the\n",
      "late\n",
      "Irene\n",
      "Adler\n",
      ",\n",
      "of\n",
      "dubious\n",
      "and\n",
      "questionable\n",
      "memory\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# DIVIDING SENTENCES INTO WORDS - TOKENIZATION\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Read in the book text\n",
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Replace newlines with spaces\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# Divide the text into words\n",
    "words = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "# Print output\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d4717f-bba8-4aec-b859-1b95cf4bfd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central\n",
      "Park\n",
      "Tower\n",
      "is\n",
      "reaaallyhiiigh\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Initialize the tweet variable\n",
    "tweet = \"@EmpireStateBldg Central Park Tower is reaaaallyhiiiigh\"\n",
    "\n",
    "# Divide the text into words\n",
    "words = \\\n",
    "nltk.tokenize.casual.casual_tokenize(tweet,\n",
    "                                    preserve_case=True,\n",
    "                                    reduce_len=True,\n",
    "                                    strip_handles=True)\n",
    "\n",
    "# Print output\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6ae1392-d420-4b19-a2a2-49262331caed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Read in the book text\u001b[39;00m\n\u001b[1;32m      4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Read in the book text\n",
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Replace newlines with spaces\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# Initialize the spaCy engine using the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Divide the text into sentences\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "\n",
    "# Print output\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c86367-17c2-4233-ac84-87604543af5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Read in the book text\u001b[39;00m\n\u001b[1;32m      3\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Read in the book text\n",
    "filename = \"/Users/dariamartinovskaya/Downloads/PLN/Chapter01/sherlock_holmes_1.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52648d6b-7a18-4bcd-9f1d-7258fb5a08c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a97fba-3085-4f90-84bf-231578ea63da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b529179-8219-45cb-9012-9e62bf230b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082dbb5-c5ab-4432-be5a-98d4c6543418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0794d3-5093-43b5-a55f-315985f7b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
