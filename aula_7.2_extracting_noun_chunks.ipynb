{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ba263dc-b527-4d6f-92fd-73e001edaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "380601dc-700f-43ae-9dd5-721b683ee8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4a7981f-8564-4596-b91c-68c99c32bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e59729c2-dea1-42ef-8f59-3c7e04374863",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eae360de-906e-499c-b5db-6223243dcdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions\n",
      "his cold, precise but admirably balanced mind\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "785b4316-ddf2-4cf7-94f4-cdc9c38df606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t 0 \t 2\n",
      "his cold, precise but admirably balanced mind \t 11 \t 19\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, \"\\t\", noun_chunk.start, \"\\t\", noun_chunk.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abdf02ec-acc4-4126-98ce-d51c2798db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n",
      "his cold, precise but admirably balanced mind \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, \"\\t\", noun_chunk.sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b207a3d0-874b-4d8c-b6ab-1eebb132721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t emotions\n",
      "his cold, precise but admirably balanced mind \t mind\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, \"\\t\", noun_chunk.root.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "683f7712-d984-4a4c-a29c-2e30881c3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_span = \"emotions\"\n",
    "other_doc = nlp(other_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50f8b1c0-22e2-4907-ad8a-143f03c02566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t 0.5081887245178223\n",
      "his cold, precise but admirably balanced mind \t 0.012711649760603905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/5w6tkw1d4tj7_rpzlm92m4hh0000gn/T/ipykernel_3178/2617387305.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(noun_chunk.text, \"\\t\", noun_chunk.similarity(other_doc))\n"
     ]
    }
   ],
   "source": [
    "#Compare noun chunk to the noun chunks in the sentence\n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, \"\\t\", noun_chunk.similarity(other_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "904de1aa-5269-4f0c-80ee-b02c57935c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18b1bf6f-6f64-4b63-b887-54989c93ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t 0.5081887245178223\n",
      "his cold, precise but admirably balanced mind \t 0.012711649760603905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/5w6tkw1d4tj7_rpzlm92m4hh0000gn/T/ipykernel_3178/1044525369.py:2: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(noun_chunk.text, \"\\t\", noun_chunk.similarity(other_doc))\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, \"\\t\", noun_chunk.similarity(other_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f1280-d96f-4806-838b-8382b08f9d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
