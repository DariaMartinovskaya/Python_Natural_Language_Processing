import nltk

# Загружаем необходимые ресурсы, если они еще не загружены
nltk.download('punkt')

# Открываем текстовый файл
filename = "sherlock_holmes_1.txt"
with open(filename, "r", encoding="utf-8") as file:
    text = file.read()

# Заменяем переводы строк пробелами
text = text.replace("\n", " ")

# Инициализируем токенизатор
tokenizer = nltk.data.load("tokenizers/punkt/english.pickle")

# Делим текст на предложения
sentences = tokenizer.tokenize(text)

# Выводим полученные предложения
for sentence in sentences:
    print(sentence)



